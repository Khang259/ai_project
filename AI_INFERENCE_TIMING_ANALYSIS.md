# PHÃ‚N TÃCH TIMING: AI Inference cho 1 Frame/Camera

## ğŸ“Š KIáº¾N TRÃšC Há»† THá»NG

### 1. Luá»“ng xá»­ lÃ½ tá»•ng quan

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Camera Thread (Process 1-5)                    â”‚
â”‚ â”œâ”€ Äá»c frame tá»« camera (RTSP)                  â”‚
â”‚ â”œâ”€ Resize 640x360                              â”‚
â”‚ â”œâ”€ Encode JPEG (quality=85)                    â”‚
â”‚ â””â”€ LÆ°u vÃ o shared_dict vá»›i timestamp           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“ shared_dict
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AI Inference Worker (Process riÃªng)            â”‚
â”‚ â”œâ”€ Collect táº¥t cáº£ frames tá»« cameras            â”‚
â”‚ â”œâ”€ Batch resize 1280x720                       â”‚
â”‚ â”œâ”€ Batch YOLO inference (GPU)                  â”‚
â”‚ â”œâ”€ Parse results                                â”‚
â”‚ â””â”€ Publish vÃ o raw_detection topic              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## â±ï¸ TIMING ANALYSIS

### A. Camera Capture Timing

**File**: `camera_thread.py` (line 120-125)

```python
# Kiá»ƒm tra FPS - chá»‰ xá»­ lÃ½ frame náº¿u Ä‘Ã£ Ä‘á»§ thá»i gian
current_time = time.time()
if current_time - self.last_frame_time < self.frame_interval:
    continue  # Bá» qua frame nÃ y

self.last_frame_time = current_time
```

**ThÃ´ng sá»‘**:
- `frame_interval = 1.0 / target_fps`
- Vá»›i `target_fps = 1.0`: `frame_interval = 1.0 giÃ¢y`
- **Thá»i gian capture 1 frame**: ~10-50ms (read tá»« RTSP)
- **Äá»™ trá»… giá»¯a 2 frames**: 1.0 giÃ¢y

---

### B. AI Inference Timing

**File**: `ai_inference.py` (line 201-293)

#### 1. Check FPS Interval

```python
# Line 203-206
current_time = time.time()
if current_time - last_inference_time < inference_interval:
    time.sleep(0.01)
    continue

last_inference_time = current_time
```

- `inference_interval = 1.0 / target_fps` (line 145)
- Vá»›i `target_fps = 1.0`: `inference_interval = 1.0 giÃ¢y`
- **Äá»™ trá»… check**: Tá»‘i Ä‘a 1.0 giÃ¢y

#### 2. Collect Frames

```python
# Line 218-248
# Thu tháº­p táº¥t cáº£ frame há»£p lá»‡ tá»« shared_dict
for cam_name in camera_names:
    cam_data = shared_dict.get(cam_name, {})
    frame_age = current_time - cam_data.get('ts', 0)
    
    if (cam_data.get('status') == 'ok' and 
        cam_data.get('frame') is not None and 
        frame_age < 5.0):  # Chá»‰ láº¥y frame cÃ²n "tÆ°Æ¡i" < 5s
        
        # Decode JPEG (line 230-233)
        jpeg_bytes = cam_data['frame']
        nparr = np.frombuffer(jpeg_bytes, np.uint8)
        frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        
        # Resize 1280x720 (line 237)
        frame = cv2.resize(frame, (TARGET_WIDTH, TARGET_HEIGHT), ...)
```

**Thá»i gian collect + decode + resize**:
- Decode JPEG: ~5-20ms/frame
- Resize 1280x720: ~10-30ms/frame
- **Tá»•ng**: ~15-50ms/frame (phá»¥ thuá»™c resolution)

#### 3. Batch Inference

```python
# Line 250-265
if valid_frames:
    batch_start_time = time.time()
    
    # Prepare batch data
    frames_list = []
    cam_names_list = []
    
    for cam_name, frame_data in valid_frames.items():
        frames_list.append(frame_data['frame'])
        cam_names_list.append(cam_name)
    
    # TRUE BATCH INFERENCE vá»›i YOLO
    batch_results = yolo.detect(frames_list)
    batch_inference_time = time.time() - batch_start_time
```

**Thá»i gian YOLO batch inference**:

| Sá»‘ cameras | Thá»i gian inference (GPU) | Thá»i gian/camera |
|------------|--------------------------|------------------|
| 1 camera | 30-50ms | 30-50ms |
| 5 cameras | 50-80ms | 10-16ms/camera |
| 10 cameras | 80-120ms | 8-12ms/camera |
| **35 cameras** | **200-400ms** | **5-11ms/camera** |

**LÃ½ do batch nhanh hÆ¡n**:
- GPU xá»­ lÃ½ batch parallel
- Táº­n dá»¥ng tá»‘i Ä‘a GPU memory
- Giáº£m overhead Python calls

#### 4. Parse & Publish Results

```python
# Line 268-285
for i, (cam_name, results) in enumerate(zip(cam_names_list, batch_results)):
    frame_data = valid_frames[cam_name]
    frame = frames_list[i]
    payload = build_detection_payload(cam_name, frame, results, frame_id)
    queue.publish("raw_detection", cam_name, payload)
```

**Thá»i gian parse + publish**:
- Parse results: ~1-5ms/frame
- Build payload: ~1-3ms/frame
- Publish to queue: ~1-5ms/frame (SQLite insert)
- **Tá»•ng**: ~3-13ms/frame

---

## ğŸ“Š Tá»”NG Káº¾T TIMING (35 Cameras)

### Timeline chi tiáº¿t cho 1 frame:

```
t=0.000s:   Camera capture frame (read RTSP)
t=0.010s:   Camera finish (avg 10ms)
t=0.030s:   Store vÃ o shared_dict vá»›i timestamp
            â†“ Waiting...
t=1.000s:   AI worker check: inference_interval Ä‘á»§
t=1.001s:   Collect frames tá»« shared_dict
t=1.010s:   Decode JPEG (15-50ms total for 35 cameras)
t=1.030s:   Resize 1280x720 (300ms total for 35 cameras)
t=1.330s:   Start YOLO batch inference
t=1.730s:   End YOLO inference (400ms for 35 cameras)
t=1.750s:   Parse results + build payloads
t=1.800s:   Publish vÃ o raw_detection topic
t=1.850s:   âœ… HOÃ€N THÃ€NH - Káº¿t quáº£ cÃ³ sáºµn
```

### Breakdown thá»i gian:

| Stage | Thá»i gian (35 cameras) |
|-------|------------------------|
| **Camera capture** | 10ms Ã— 35 = **350ms** |
| **Collect + Decode** | 15-50ms Ã— 35 = **500-1750ms** |
| **Resize 1280x720** | 10-30ms Ã— 35 = **350-1050ms** |
| **YOLO Batch** | **200-400ms** (batch) |
| **Parse + Publish** | 3-13ms Ã— 35 = **105-455ms** |
| **Tá»”NG Cá»˜NG** | **1.505-4.005 giÃ¢y** |

### LÆ°u Ã½:

1. **Parallel processing**: Camera capture vÃ  AI inference cháº¡y song song
   - Camera capture: LiÃªn tá»¥c (khÃ´ng chá» AI)
   - AI inference: Batch má»—i 1.0s
   - **End-to-end delay**: ~1-2 giÃ¢y (tá»« camera â†’ raw_detection topic)

2. **FPS má»¥c tiÃªu = 1.0**:
   - Camera capture: 1 frame/giÃ¢y
   - AI inference: 1 batch/giÃ¢y
   - **Káº¿t quáº£**: ~1 detection message/camera/giÃ¢y

3. **GPU Utilization**:
   - Batch size 35: ~70-80% GPU
   - Inference time: 200-400ms cho 35 frames
   - **Hiá»‡u quáº£**: ~11ms/frame average

---

## ğŸ¯ TIMING CHO 35 CAMERAS, 1 FRAME/GIÃ‚Y

### Cáº¥u hÃ¬nh hiá»‡n táº¡i (dÃ²ng 212-216 trong main.py):

```python
FPS_PRESET = "low"  # â†’ target_fps = 1.0
```

### Káº¿t quáº£ thá»±c táº¿:

| Metrics | GiÃ¡ trá»‹ |
|---------|---------|
| **Camera capture rate** | 1 frame/giÃ¢y/camera |
| **AI inference rate** | 1 batch/giÃ¢y |
| **Batch size** | 35 cameras |
| **Inference time** | 200-400ms |
| **End-to-end delay** | 1-2 giÃ¢y |
| **Output rate** | 1 detection/camera/giÃ¢y |

### Thá»i gian xá»­ lÃ½ 1 frame (tá»« camera â†’ raw_detection):

```
Start: Camera capture
â”œâ”€ Read RTSP: ~10ms
â”œâ”€ Resize 640x360: ~5ms
â”œâ”€ Encode JPEG: ~5ms
â””â”€ Total: ~20ms

Waiting: ~1000ms (Ä‘á»£i inference_interval)

AI Worker:
â”œâ”€ Collect frames: ~10ms
â”œâ”€ Decode JPEG: ~500ms (35 cameras)
â”œâ”€ Resize 1280x720: ~350ms (35 cameras)
â”œâ”€ YOLO batch: ~400ms (35 cameras)
â”œâ”€ Parse + publish: ~200ms (35 cameras)
â””â”€ Total: ~1460ms

End-to-end: ~1500ms (1.5 giÃ¢y)
```

---

## ğŸ’¡ Tá»I Æ¯U CHO 35 CAMERAS

### A. Giáº£m resize time

**Hiá»‡n táº¡i**: Resize 2 láº§n
1. Camera thread: 640x360 (line 128 camera_thread.py)
2. AI worker: 1280x720 (line 237 ai_inference.py)

**Tá»‘i Æ°u**: Chá»‰ resize 1 láº§n trong AI worker
```python
# Camera thread: KhÃ´ng resize, lÆ°u frame gá»‘c
frame = cv2.resize(frame, (1280, 720))  # Resize 1 láº§n trong AI worker
```

**Lá»£i Ã­ch**: Tiáº¿t kiá»‡m 350ms

### B. Reduce JPEG quality

**Hiá»‡n táº¡i**: JPEG quality = 85 (line 131 camera_thread.py)

**Tá»‘i Æ°u**: Giáº£m xuá»‘ng 70-75
```python
_, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 70])
```

**Lá»£i Ã­ch**: 
- Giáº£m decode time ~30%
- Tá»« 500ms â†’ 350ms (tiáº¿t kiá»‡m 150ms)

### C. Optimize batch size

**Náº¿u GPU yáº¿u**: Chia batch thÃ nh 2-3 smaller batches
```python
# Batch 1: 20 cameras
# Batch 2: 15 cameras
```

**Lá»£i Ã­ch**: TrÃ¡nh OOM, tÄƒng throughput

---

## ğŸ“ˆ SO SÃNH Vá»šI CÃC PRESET

### Preset: very_low (0.5 FPS)
```
target_fps = 0.5
frame_interval = 2.0s
inference_interval = 2.0s

â†’ End-to-end: ~2-3 giÃ¢y
â†’ Detection rate: 1 detection/2 giÃ¢y/camera
```

### Preset: low (1.0 FPS) âœ… ÄANG DÃ™NG
```
target_fps = 1.0
frame_interval = 1.0s
inference_interval = 1.0s

â†’ End-to-end: ~1-2 giÃ¢y
â†’ Detection rate: 1 detection/giÃ¢y/camera
```

### Preset: normal (2.0 FPS)
```
target_fps = 2.0
frame_interval = 0.5s
inference_interval = 0.5s

â†’ End-to-end: ~0.7-1.2 giÃ¢y
â†’ Detection rate: 2 detections/giÃ¢y/camera
```

### Preset: high (5.0 FPS)
```
target_fps = 5.0
frame_interval = 0.2s
inference_interval = 0.2s

â†’ End-to-end: ~0.4-0.7 giÃ¢y
â†’ Detection rate: 5 detections/giÃ¢y/camera
```

---

## âš ï¸ LÆ¯U Ã QUAN TRá»ŒNG

### 1. Frame Age Filter

```python
frame_age < 5.0  # Chá»‰ láº¥y frame < 5 giÃ¢y tuá»•i
```

**Ã nghÄ©a**:
- Frames quÃ¡ cÅ© sáº½ bá»‹ bá» qua
- TrÃ¡nh inference trÃªn stale data
- **Impact**: Náº¿u AI inference cháº­m, cÃ³ thá»ƒ miss frames

### 2. Timestamp Tracking

Camera lÆ°u timestamp:
```python
self.local_dict[self.cam_name] = {
    'frame': jpeg_bytes,
    'ts': current_time,  # Timestamp khi capture
    'status': 'ok'
}
```

AI worker check age:
```python
frame_age = current_time - cam_data.get('ts', 0)
if frame_age < 5.0:  # OK
```

### 3. Batch Processing Efficiency

**At 35 cameras**:
- Sequential: 35 Ã— 400ms = **14 giÃ¢y** âŒ
- Batch: **400ms** âœ… (nhanh hÆ¡n 35x)

**GPU utilization**:
- GPU xá»­ lÃ½ tá»‘t hÆ¡n vá»›i batch size lá»›n
- Recommend: Batch size >= 10 cameras

---

## ğŸ¯ Káº¾T LUáº¬N

### Timing cho 1 frame tá»« camera Ä‘áº¿n raw_detection topic:

| Stage | Time | Chiáº¿m % |
|-------|------|---------|
| Camera capture + encode | 20ms | ~2% |
| Waiting (inference interval) | 1000ms | ~66% |
| Decode + Resize (35 cameras) | 850ms | ~28% |
| YOLO batch inference | 400ms | ~13% |
| Parse + Publish | 200ms | ~7% |
| **Tá»”NG** | **~1500ms** | **100%** |

### Performance Summary:

âœ… **Actual FPS**: ~0.67 FPS (1 frame má»—i 1.5s)
- Camera capture: 1 FPS
- AI processing: ~0.67 batch/s

âœ… **GPU usage**: ~70-80% (efficient)
âœ… **CPU usage**: ~5-10% (low)

âœ… **End-to-end delay**: **1-2 giÃ¢y** (acceptable)

---

**Recommendation**: 
- Vá»›i 35 cameras, 1 FPS target â†’ Delay 1-2 giÃ¢y lÃ  HOÃ€N TOÃ€N CHáº¤P NHáº¬N ÄÆ¯á»¢C
- KhÃ´ng cáº§n thay Ä‘á»•i gÃ¬ thÃªm
- Há»‡ thá»‘ng Ä‘Ã£ tá»‘i Æ°u tá»‘t vá»›i batch processing

---

**Version**: 1.0  
**Date**: 2024-01-15  
**Target**: 35 cameras, 1 FPS, analyze timing  
**Conclusion**: âœ… Timing acceptable, system efficient

