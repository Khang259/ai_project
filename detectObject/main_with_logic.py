"""
Main v·ªõi Logic Processor ƒë√£ t√≠ch h·ª£p
ƒê√¢y l√† phi√™n b·∫£n main.py c√≥ th√™m Logic Processor

C√°ch ch·∫°y:
    cd D:\WORK\ROI_LOGIC_version2\detectObject
    python main_with_logic.py [options]
"""

import multiprocessing as mp
from multiprocessing import Manager, Process, Queue
import time
import math
from typing import List, Tuple, Optional
import json
from pathlib import Path
import argparse
import sys

from camera_process import camera_process_worker
from ai_inference import ai_inference_worker
from roi_checker import roi_checker_worker, roi_result_consumer
from roi_visualizer import roi_visualizer_worker
from config import camera_config, ai_config, system_config, validate_config, print_config

# Import Logic Processor
sys.path.insert(0, str(Path(__file__).parent.parent))
from logic import logic_processor_worker


def output_handler_worker(output_queue: Queue):
    """
    Worker x·ª≠ l√Ω output t·ª´ Logic Processor (Queue B - logic_output_queue)
    ƒê√¢y l√† n∆°i b·∫°n c√≥ th·ªÉ:
    - G·ª≠i API request
    - L∆∞u v√†o database
    - G·ª≠i notifications
    - Trigger actions kh√°c
    """
    print("üì• Output Handler Worker started (Reading from Queue B)\n")
    
    trigger_count = 0
    
    try:
        while True:
            try:
                # Log tr∆∞·ªõc khi get t·ª´ queue
                queue_size_before = output_queue.qsize()
                
                # Get t·ª´ Queue B
                output = output_queue.get(timeout=1.0)
                trigger_count += 1
                
                queue_size_after = output_queue.qsize()
                
                # Log khi nh·∫≠n ƒë∆∞·ª£c t·ª´ Queue B
                print(f"\n{'='*60}")
                print(f"üì• RECEIVED FROM QUEUE B (logic_output_queue)")
                print(f"{'='*60}")
                print(f"Queue Size: {queue_size_before} ‚Üí {queue_size_after} (after get)")
                print(f"Trigger #: {trigger_count}")
                print(f"Rule: {output.get('rule_name', 'unknown')} ({output.get('rule_type', 'unknown')})")
                print(f"Timestamp: {output.get('timestamp', 0)}")
                print(f"Stable Duration: {output.get('stable_duration', 0):.2f}s")
                print(f"Output Queue: {output.get('output_queue', 'N/A')}")
                
                # X·ª≠ l√Ω theo lo·∫°i rule
                if output['rule_type'] == 'Pairs':
                    print(f"\nüìç 3-Point Status:")
                    print(f"   s1 ({output['s1']['qr_code']}): {output['s1']['state']} "
                          f"[conf: {output['s1']['confidence']:.2f}]")
                    print(f"   e1 ({output['e1']['qr_code']}): {output['e1']['state']} "
                          f"[conf: {output['e1']['confidence']:.2f}]")
                    print(f"   e2 ({output['e2']['qr_code']}): {output['e2']['state']} "
                          f"[conf: {output['e2']['confidence']:.2f}]")
                    
                    # TODO: G·ª≠i API request, l∆∞u DB, etc.
                    # api_response = send_to_external_api(output)
                    
                elif output['rule_type'] == 'Dual':
                    print(f"\nüìç Pair Status: {output.get('pair', 'N/A')}")
                    print(f"   s ({output['s']['qr_code']}): {output['s']['state']} "
                          f"[conf: {output['s']['confidence']:.2f}]")
                    print(f"   e ({output['e']['qr_code']}): {output['e']['state']} "
                          f"[conf: {output['e']['confidence']:.2f}]")
                
                print(f"{'='*60}")
                print(f"‚úÖ Processing trigger #{trigger_count} from Queue B")
                print(f"{'='*60}\n")
                
            except:
                time.sleep(0.01)
                
    except KeyboardInterrupt:
        print(f"\n\nüëã Output Handler stopped. Total triggers processed: {trigger_count}")


class CameraOrchestrator:
    """Orchestrator ch√≠nh qu·∫£n l√Ω to√†n b·ªô h·ªá th·ªëng"""
    
    def __init__(self, 
                 camera_urls: List[Tuple[str, str]], 
                 num_processes: Optional[int] = None, 
                 max_retry_attempts: Optional[int] = None, 
                 use_ai: Optional[bool] = None, 
                 model_path: Optional[str] = None, 
                 target_fps: Optional[float] = None,
                 enable_visualization: Optional[bool] = True,
                 enable_logic_processor: Optional[bool] = True):
        """
        Args:
            camera_urls: List c√°c URL camera [(name, url), ...]
            num_processes: S·ªë process (m·∫∑c ƒë·ªãnh t·ª´ config)
            max_retry_attempts: S·ªë l·∫ßn th·ª≠ k·∫øt n·ªëi l·∫°i t·ªëi ƒëa (m·∫∑c ƒë·ªãnh t·ª´ config)
            use_ai: C√≥ s·ª≠ d·ª•ng AI detection kh√¥ng (m·∫∑c ƒë·ªãnh t·ª´ config)
            model_path: ƒê∆∞·ªùng d·∫´n model YOLO .pt (m·∫∑c ƒë·ªãnh t·ª´ config)
            target_fps: FPS m·ª•c ti√™u cho camera v√† AI (m·∫∑c ƒë·ªãnh t·ª´ config)
            enable_visualization: C√≥ hi·ªÉn th·ªã visualization kh√¥ng (m·∫∑c ƒë·ªãnh: True)
            enable_logic_processor: C√≥ ch·∫°y Logic Processor kh√¥ng (m·∫∑c ƒë·ªãnh: True)
        """
        # Validate config tr∆∞·ªõc khi kh·ªüi ƒë·ªông
        if not validate_config():
            raise ValueError("Config kh√¥ng h·ª£p l·ªá. Vui l√≤ng ki·ªÉm tra l·∫°i.")
        
        self.camera_urls = camera_urls
        self.num_processes = num_processes or system_config.NUM_CAMERA_PROCESSES
        self.max_retry_attempts = max_retry_attempts or camera_config.MAX_RETRY_ATTEMPTS
        self.use_ai = use_ai if use_ai is not None else system_config.USE_AI
        self.model_path = model_path or ai_config.DEFAULT_MODEL_PATH
        self.target_fps = target_fps or camera_config.TARGET_FPS
        self.enable_visualization = enable_visualization
        self.enable_logic_processor = enable_logic_processor
        
        self.manager = Manager()
        self.shared_dict = self.manager.dict()
        self.result_dict = self.manager.dict()
        self.detection_queue = Queue(maxsize=1000)  # AI ‚Üí ROI Checker
        self.roi_result_queue = Queue(maxsize=1000)  # ROI Checker ‚Üí Logic Processor (Queue 1)
        self.logic_output_queue = Queue(maxsize=1000)  # Logic Processor ‚Üí Output (Queue 2)
        self.processes = []
        
    def _divide_cameras(self) -> List[List[Tuple[str, str]]]:
        """Chia nh√≥m camera cho c√°c process"""
        total_cameras = len(self.camera_urls)
        cameras_per_process = math.ceil(total_cameras / self.num_processes)
        
        camera_groups = []
        for i in range(0, total_cameras, cameras_per_process):
            group = self.camera_urls[i:i + cameras_per_process]
            camera_groups.append(group)
        
        return camera_groups
    
    def start(self):
        """Kh·ªüi ƒë·ªông h·ªá th·ªëng"""
        # In c·∫•u h√¨nh
        print_config()
        
        # Chia nh√≥m camera
        camera_groups = self._divide_cameras()
        
        # T·∫°o v√† spawn c√°c process camera
        for i, camera_group in enumerate(camera_groups):
            process = Process(
                target=camera_process_worker,
                args=(i, camera_group, self.shared_dict, self.max_retry_attempts, self.target_fps)
            )
            self.processes.append(process)
            process.start()
        
        if self.use_ai:
            # AI Inference Worker
            ai_process = Process(
                target=ai_inference_worker,
                args=(self.shared_dict, self.result_dict, self.detection_queue, self.model_path, ai_config.TARGET_FPS)
            )
            self.processes.append(ai_process)
            ai_process.start()
            
            # ROI Checker Worker
            roi_checker_process = Process(
                target=roi_checker_worker,
                args=(self.detection_queue, self.roi_result_queue, "../logic/roi_config.json", 0.3, 0.6)
            )
            self.processes.append(roi_checker_process)
            roi_checker_process.start()
            
            # Logic Processor Worker (M·ªöI TH√äM)
            if self.enable_logic_processor:
                print("\n Starting Logic Processor...")
                logic_processor_process = Process(
                    target=logic_processor_worker,
                    args=(self.roi_result_queue, self.logic_output_queue, "../logic/config.json")
                )
                self.processes.append(logic_processor_process)
                logic_processor_process.start()
                print(" Logic Processor started\n")
                
                # Output Handler Worker (M·ªöI TH√äM)
                output_handler_process = Process(
                    target=output_handler_worker,
                    args=(self.logic_output_queue,)
                )
                self.processes.append(output_handler_process)
                output_handler_process.start()
                print(" Output Handler started\n")
            
            # ROI Result Consumer (ch·ªâ khi kh√¥ng d√πng visualizer v√† kh√¥ng d√πng logic processor)
            if not self.enable_visualization and not self.enable_logic_processor:
                roi_consumer_process = Process(
                    target=roi_result_consumer,
                    args=(self.roi_result_queue,)
                )
                self.processes.append(roi_consumer_process)
                roi_consumer_process.start()
            
            # ROI Visualizer (n·∫øu ƒë∆∞·ª£c b·∫≠t)
            if self.enable_visualization:
                visualizer_process = Process(
                    target=roi_visualizer_worker,
                    args=(self.shared_dict, self.roi_result_queue, "../logic/roi_config.json", 640, 360, 15.0)
                )
                self.processes.append(visualizer_process)
                visualizer_process.start()
    
    def run_lifecycle(self):
        """Ch·∫°y v√≤ng ƒë·ªùi h·ªá th·ªëng"""
        try:
            while True:
                time.sleep(system_config.STATUS_DISPLAY_INTERVAL)
                
                # Hi·ªÉn th·ªã th·ªëng k√™
                active_cameras = len(self.shared_dict)
                ok_cameras = sum(1 for cam_data in self.shared_dict.values() 
                               if cam_data.get('status') == 'ok')
                
                print(f"Camera: {ok_cameras}/{active_cameras} OK | Logic: {'ON' if self.enable_logic_processor else 'OFF'}", end='\r')
                
        except KeyboardInterrupt:
            self._stop()
    
    def _stop(self):
        """D·ª´ng t·∫•t c·∫£ process"""
        for process in self.processes:
            process.terminate()
        
        timeout = system_config.PROCESS_TERMINATE_TIMEOUT
        
        for process in self.processes:
            process.join(timeout=timeout)


def load_camera_config(config_file: str = "camera_config.json") -> dict:
    """Load c·∫•u h√¨nh camera t·ª´ file JSON"""
    config_path = Path(__file__).parent / config_file
    
    if not config_path.exists():
        return {}
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        return config
    except Exception:
        return {}


def main():
    """Main function - kh·ªüi ƒë·ªông h·ªá th·ªëng camera v·ªõi Logic Processor"""
    
    # Parse command-line arguments
    parser = argparse.ArgumentParser(
        description='H·ªá th·ªëng Camera Detection v·ªõi AI v√† Logic Processor',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
V√≠ d·ª• s·ª≠ d·ª•ng:
  python main_with_logic.py                    # Ch·∫°y ƒë·∫ßy ƒë·ªß v·ªõi Logic Processor
  python main_with_logic.py --no-video         # T·∫Øt visualization
  python main_with_logic.py --no-logic         # T·∫Øt Logic Processor
  python main_with_logic.py --no-ai            # T·∫Øt AI detection
  python main_with_logic.py --model custom.pt  # S·ª≠ d·ª•ng model t√πy ch·ªânh
  python main_with_logic.py --fps 3.0          # ƒê·∫∑t FPS cho AI inference
        """
    )
    
    parser.add_argument('--no-video', action='store_true',
                       help='T·∫Øt visualization window')
    parser.add_argument('--no-logic', action='store_true',
                       help='T·∫Øt Logic Processor')
    parser.add_argument('--no-ai', action='store_true',
                       help='T·∫Øt AI detection')
    parser.add_argument('--model', type=str, default=None,
                       help='ƒê∆∞·ªùng d·∫´n model YOLO custom')
    parser.add_argument('--fps', type=float, default=None,
                       help='FPS m·ª•c ti√™u cho AI inference')
    parser.add_argument('--processes', type=int, default=None,
                       help='S·ªë l∆∞·ª£ng camera process')
    parser.add_argument('--config', type=str, default='camera_config.json',
                       help='ƒê∆∞·ªùng d·∫´n file c·∫•u h√¨nh camera')
    
    args = parser.parse_args()

    # Load camera config t·ª´ file
    config = load_camera_config(args.config)

    # L·∫•y danh s√°ch camera t·ª´ config
    camera_urls = [
        (cam['name'], cam['url']) 
        for cam in config.get('cameras', [])
        if cam.get('enabled', True)
    ]
    
    if not camera_urls:
        return

    # L·∫•y system settings
    system_settings = config.get('system', {})
    num_processes = args.processes or system_settings.get('num_processes', system_config.NUM_CAMERA_PROCESSES)
    use_ai = system_settings.get('use_ai', system_config.USE_AI) and not args.no_ai
    model_path = args.model or system_settings.get('model_path', ai_config.DEFAULT_MODEL_PATH)

    # L·∫•y camera settings
    camera_settings = config.get('camera_settings', {})
    max_retry = camera_settings.get('max_retry_attempts', camera_config.MAX_RETRY_ATTEMPTS)
    camera_fps = args.fps or camera_settings.get('target_fps', camera_config.TARGET_FPS)
    
    # T·∫°o orchestrator
    orchestrator = CameraOrchestrator(
        camera_urls=camera_urls,
        num_processes=num_processes,
        max_retry_attempts=max_retry,
        use_ai=use_ai,
        model_path=model_path,
        target_fps=camera_fps,
        enable_visualization=not args.no_video,
        enable_logic_processor=not args.no_logic and use_ai  # Logic c·∫ßn AI
    )
    
    # Kh·ªüi ƒë·ªông v√† ch·∫°y
    orchestrator.start()
    orchestrator.run_lifecycle()

if __name__ == "__main__":
    main()

